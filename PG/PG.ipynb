{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "A2_PG.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iDlHasN5oeK"
      },
      "source": [
        "import xlrd\n",
        "import re\n",
        "from random import randrange"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpuPNiDp6rjH"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvRoECWL5oeY"
      },
      "source": [
        "# Read file\n",
        "def read_file(file_loc):\n",
        "  wb = xlrd.open_workbook(file_loc) \n",
        "  sheet = wb.sheet_by_index(0)\n",
        "  raw_data = []\n",
        "  for i in range(sheet.nrows): \n",
        "      raw_data.append(sheet.cell_value(i, 0))\n",
        "  return raw_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfEQeP0Z5oei"
      },
      "source": [
        "#Pre-processing i.e removing noise from data\n",
        "def pre_processing(raw_data):\n",
        "  word_removal_list = [(\"؛ ٫ / - . \\ ! ؟ ۔ ٪ a b c d e f g h i j k l m n o p q r s t u v w x y z 0 1 2 3 4 5 6 7 8 9\".split())]\n",
        "  refined_data = []\n",
        "  for i in range(len(raw_data)):\n",
        "    punctuation_removed = []\n",
        "    for j in range(len(word_removal_list[0])):\n",
        "      if (j==0):\n",
        "        punctuation_removed.append(raw_data[i].replace(word_removal_list[0][j],''))\n",
        "        punctuation_removed.append(punctuation_removed[-1].replace('،',' ، '))\n",
        "      else:\n",
        "        punctuation_removed.append(punctuation_removed[-1].replace(word_removal_list[0][j],''))\n",
        "    refined_data.append(punctuation_removed[-1])\n",
        "  return refined_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "L4XU7pR55oet"
      },
      "source": [
        "#Tokenization\n",
        "def generate_token(refined_data):\n",
        "  tokenz = []\n",
        "  for i in range(len(refined_data)):\n",
        "    tokenz.append(re.findall(r'[،^آ-ۓ][^ ]*',refined_data[i])) # Find all the words which are separated by space and tokenize\n",
        "  return tokenz\n",
        "\n",
        "# For Standard n-grams\n",
        "def standard_tokenize(refined_data):\n",
        "  ngram_token = []\n",
        "  for i in range(len(refined_data)):\n",
        "    new_data = refined_data[i].replace(' ، ',' ')\n",
        "    ngram_token.append(re.findall(r'[آ-ۓ][^ ]*',new_data))\n",
        "  return ngram_token\n",
        "\n",
        "# For Backward Bigram\n",
        "def backward_tokenize(normal_token):\n",
        "  reversed_token = []\n",
        "  for i in range(len(normal_token)):\n",
        "    reversed_token.append(normal_token[i][::-1])\n",
        "  return reversed_token"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daGsvr0AV_eC"
      },
      "source": [
        "# A list of starting words \n",
        "# I am only taking the words of first 2 verses of each stanza in the dataset\n",
        "def generate_starting_words(tokens):\n",
        "  starting_words = []\n",
        "  for i in range(len(tokens)):\n",
        "    if (('،') in tokens[i]):\n",
        "      starting_words.append(tokens[i][0])\n",
        "      starting_words.append(tokens[i][tokens[i].index('،')+1])\n",
        "  return starting_words\n",
        "\n",
        "def generate_starting_two_words(tokens):\n",
        "  starting_two_words = []\n",
        "  for i in range(len(tokens)):\n",
        "    if (('،') in tokens[i]):\n",
        "      starting_two_words.append(tokens[i][0]+' '+tokens[i][1])\n",
        "      starting_two_words.append(tokens[i][tokens[i].index('،')+1]+' '+tokens[i][tokens[i].index('،')+2])\n",
        "  return starting_two_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOrUJ48D5oe4"
      },
      "source": [
        "#Get Unigrams and their count\n",
        "def generate_unigram(ngram_token):\n",
        "  unigram = []\n",
        "  c_unigram = []\n",
        "  for i in range(len(ngram_token)):\n",
        "    for j in range(len(ngram_token[i])):\n",
        "      if (ngram_token[i][j] not in unigram):\n",
        "        unigram.append(ngram_token[i][j])\n",
        "        c_unigram.append(1)\n",
        "      else:\n",
        "        c_unigram[unigram.index(ngram_token[i][j])] += 1 \n",
        "  return unigram,c_unigram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "fTRKD-0W5ofA"
      },
      "source": [
        "#Unigram probabilities\n",
        "def generate_unigram_prob(unigram,c_unigram):\n",
        "  Prob_unigram = []\n",
        "  for i in range(len(unigram)):\n",
        "    Prob_unigram.append(c_unigram[i]/len(unigram))\n",
        "  return Prob_unigram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDDsr4av5ofH"
      },
      "source": [
        "#Get Bigrams and their count\n",
        "def generate_bigram(ngram_token):\n",
        "  bigram = []\n",
        "  c_bigram = []\n",
        "  for i in range(len(ngram_token)):\n",
        "    for j in range(len(ngram_token[i])-1):\n",
        "      if ((ngram_token[i][j]+' '+ngram_token[i][j+1]) not in bigram):\n",
        "        bigram.append(ngram_token[i][j]+' '+ngram_token[i][j+1])\n",
        "        c_bigram.append(1)\n",
        "      else:\n",
        "        c_bigram[bigram.index(ngram_token[i][j]+' '+ngram_token[i][j+1])] +=1\n",
        "  return bigram,c_bigram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X8kFBiN5ofM"
      },
      "source": [
        "#bigram probabilities\n",
        "def generate_bigram_prob(bigram,c_bigram):\n",
        "  Prob_bigram = []\n",
        "  for i in range(len(bigram)):\n",
        "    Prob_bigram.append(c_bigram[i]/len(bigram))\n",
        "  return Prob_bigram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAU-Ase85ofS"
      },
      "source": [
        "#Trigrams and their count\n",
        "def generate_trigram(ngram_token):\n",
        "  trigram = []\n",
        "  c_trigram = []\n",
        "  for i in range(len(ngram_token)):\n",
        "    for j in range(len(ngram_token[i])-2):\n",
        "      if ((ngram_token[i][j]+' '+ngram_token[i][j+1]+' '+ngram_token[i][j+2]) not in trigram):\n",
        "        trigram.append(ngram_token[i][j]+' '+ngram_token[i][j+1]+' '+ngram_token[i][j+2])\n",
        "        c_trigram.append(1)\n",
        "      else:\n",
        "        c_trigram[trigram.index(ngram_token[i][j]+' '+ngram_token[i][j+1]+' '+ngram_token[i][j+2])] +=1\n",
        "  return trigram,c_trigram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYMnt0Sy5ofZ"
      },
      "source": [
        "#trigram probabilities\n",
        "def generate_trigram_prob(trigram,c_trigram):\n",
        "  Prob_trigram = []\n",
        "  for i in range(len(trigram)):\n",
        "    Prob_trigram.append(c_trigram[i]/len(trigram))\n",
        "  return Prob_trigram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlhG6V4JY4W0"
      },
      "source": [
        "# Generation of verses using bigrams\n",
        "def generate_stanza_bigram(lenverse,bigram,Prob_bigram,starting_words):\n",
        "  stanza = []\n",
        "  for j in range(4): # Size of Stanza\n",
        "    verse = []\n",
        "    rand_index = randrange(len(starting_words))\n",
        "    verse.append(starting_words[rand_index])\n",
        "    for i in range(lenverse):\n",
        "      valid_next_word = []\n",
        "      prob_next_word = []\n",
        "      given_that_this_word = verse[len(verse)-1] + ' '\n",
        "      for k in range(len(bigram)):\n",
        "        if (given_that_this_word in bigram[k]):\n",
        "          valid_next_word.append(bigram[k])\n",
        "          prob_next_word.append(Prob_bigram[k])\n",
        "      next_word_bigram = valid_next_word[prob_next_word.index(max(prob_next_word))]\n",
        "      extract_word = r' [آ-ۓ]*'\n",
        "      next_word = re.findall(extract_word,next_word_bigram)\n",
        "      final = next_word[0].replace(\" \",\"\")\n",
        "      verse.append(final)\n",
        "    comp_verse = \"\"\n",
        "    for x in range(len(verse)):\n",
        "      if (x!=len(verse)-1):\n",
        "        comp_verse+=verse[x]+ ' '\n",
        "      else:\n",
        "        comp_verse+=verse[x]\n",
        "    # print(comp_verse)\n",
        "    stanza.append(comp_verse)\n",
        "  comp_stanza = \"\"\n",
        "  for y in range(len(stanza)):\n",
        "      comp_stanza+=stanza[y]+'\\n'\n",
        "  return comp_stanza"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "regmcVoK9hb5"
      },
      "source": [
        "# Generation of verses using trigrams\n",
        "def generate_stanza_trigram(lenverse,trigram,Prob_trigram,Prob_bigram,bigram,starting_words):\n",
        "  stanza = []\n",
        "  for j in range(4):\n",
        "    verse = []\n",
        "    rand_index = randrange(len(starting_words))\n",
        "    verse.append(starting_words[rand_index])\n",
        "    # Get second word using bigram\n",
        "    valid_next_word = []\n",
        "    prob_next_word = []\n",
        "    given_that_this_word = verse[len(verse)-1] + ' '\n",
        "    for k in range(len(bigram)):\n",
        "      if (given_that_this_word in bigram[k]):\n",
        "        valid_next_word.append(bigram[k])\n",
        "        prob_next_word.append(Prob_bigram[k])\n",
        "    next_word_bigram = valid_next_word[prob_next_word.index(max(prob_next_word))]\n",
        "    extract_word_regex = r' [آ-ۓ]*'\n",
        "    next_word = re.findall(extract_word_regex,next_word_bigram)\n",
        "    final = next_word[0].replace(\" \",\"\")\n",
        "    verse.append(final)\n",
        "    # Get other words using trigrams\n",
        "    for i in range(lenverse):\n",
        "      valid_next_word_trigram = []\n",
        "      prob_next_word_trigram = []\n",
        "      given_that_these_words = verse[len(verse)-2] + ' ' + verse[len(verse)-1] + ' '\n",
        "      for j in range(len(trigram)):\n",
        "        if (given_that_these_words in trigram[j]):\n",
        "          valid_next_word_trigram.append(trigram[j])\n",
        "          prob_next_word_trigram.append(prob_trigram[j])\n",
        "      next_word_trigram = valid_next_word_trigram[prob_next_word_trigram.index(max(prob_next_word_trigram))]\n",
        "      extract_word_regex = r' [آ-ۓ]*'\n",
        "      next_word = re.findall(extract_word_regex,next_word_trigram)\n",
        "      final_word = next_word[1].replace(' ','')\n",
        "      verse.append(final_word)\n",
        "    comp_verse = \"\"\n",
        "    for x in range(len(verse)):\n",
        "      if (x!=len(verse)-1):\n",
        "        comp_verse+=verse[x]+ ' '\n",
        "      else:\n",
        "        comp_verse+=verse[x]\n",
        "    # print(comp_verse)\n",
        "    stanza.append(comp_verse)\n",
        "  comp_stanza = \"\"\n",
        "  for y in range(len(stanza)):\n",
        "    comp_stanza+=stanza[y]+'\\n'\n",
        "  return comp_stanza"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXk4R-0dwTXX"
      },
      "source": [
        "#Main \n",
        "file_loc = (\"/content/drive/My Drive/Poetry_Dataset.xlsx\")\n",
        "raw_data = read_file(file_loc)\n",
        "refined_data = pre_processing(raw_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgNB4Z8kyzAu"
      },
      "source": [
        "tokens = generate_token(refined_data)\n",
        "ngram_token = standard_tokenize(refined_data)\n",
        "reverse_token = backward_tokenize(ngram_token)\n",
        "starting_words = generate_starting_words(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exMPa2Xry1Px"
      },
      "source": [
        "unigram,count_unigram = generate_unigram(ngram_token)\n",
        "prob_unigram = generate_unigram_prob(unigram,count_unigram)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y05DKZDOy5e4"
      },
      "source": [
        "bigram,count_bigram = generate_bigram(ngram_token)\n",
        "prob_bigram = generate_bigram_prob(bigram,count_bigram)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWgHPFHMy6z-"
      },
      "source": [
        "reverse_bigram,count_reverse_bigram = generate_bigram(reverse_token)\n",
        "prob_reverse_bigram = generate_bigram_prob(reverse_bigram,count_reverse_bigram)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8zkl9vQ8nJO"
      },
      "source": [
        "trigram,count_trigram = generate_trigram(ngram_token)\n",
        "prob_trigram = generate_trigram_prob(trigram,count_trigram)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdcUuQuwziuh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "61ef8fcf-a36a-4f04-f559-859e12c2a158"
      },
      "source": [
        "lenverse = randrange(3,7) \n",
        "stanzas = []\n",
        "print('Length of each verse is: ',lenverse+1)\n",
        "for i in range(3):\n",
        "  stanzas.append(generate_stanza_bigram(lenverse,bigram,prob_bigram,starting_words))\n",
        "for x in range(3):\n",
        "  print(stanzas[x])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of each verse is:  4\n",
            "نیا میں نے میں\n",
            "میں نے میں نے\n",
            "نیند میں نے میں\n",
            "خود کو بھی نہیں\n",
            "\n",
            "تمہارے ساتھ ہیں ہے\n",
            "زندہ ہوں میں نے\n",
            "آندھیوں کے لیے ہے\n",
            "دوستی کا ہے کہ\n",
            "\n",
            "عشق میں نے میں\n",
            "لگتی ہے کہ میں\n",
            "انساں کا ہے کہ\n",
            "میں نے میں نے\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3ltnKhy2krl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "14cea29a-1027-4305-9d62-2fc3b3e6f8c5"
      },
      "source": [
        "lenverse_reverse_bigram = randrange(3,7) \n",
        "stanzas_reverse_bigram = []\n",
        "print('Length of each verse is: ',lenverse_reverse_bigram+1)\n",
        "for i in range(3):\n",
        "  stanzas_reverse_bigram.append(generate_stanza_bigram(lenverse_reverse_bigram,reverse_bigram,prob_reverse_bigram,starting_words))\n",
        "for x in range(3):\n",
        "  print(stanzas_reverse_bigram[x])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of each verse is:  4\n",
            "گہرے کے اس ہے\n",
            "فسانہ ہی جا کے\n",
            "آدمی ہے نہیں بھی\n",
            "ویرانیاں کارواں اور ہے\n",
            "\n",
            "مذہبی بہت ہے نہیں\n",
            "روبرو کے اس ہے\n",
            "یہ ہے نہیں بھی\n",
            "سمجھے کیا میں ہوں\n",
            "\n",
            "جب ہے نہیں بھی\n",
            "تو ہے نہیں بھی\n",
            "ناک ہے نہیں بھی\n",
            "مانا جاناں ہے نہیں\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0MEcKgCTCDF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "b5188ad3-227d-4711-bb22-c0e448d894fd"
      },
      "source": [
        "lenverse_trigram = randrange(3,7) \n",
        "stanzas_trigram = []\n",
        "print('Length of each verse is: ',lenverse_trigram+2)\n",
        "for i in range(3):\n",
        "  stanzas_trigram.append(generate_stanza_trigram(lenverse_trigram,trigram,prob_trigram,prob_bigram,bigram,starting_words))\n",
        "for x in range(3):\n",
        "  print(stanzas_trigram[x])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of each verse is:  6\n",
            "سلگ رہی ہوں میں خود سے\n",
            "مزہ آتا ھے مجھ سے کم\n",
            "جنوں کی راہ میں دل کو\n",
            "اُس کے ہاتھ میں ہے وہ\n",
            "\n",
            "تاروں کی طرح تھا وہ بھی\n",
            "کوئی نہیں ہے یہ کس کی\n",
            "مقتل میں ہیں جینے کی دعا\n",
            "من میں جھانک کے دیکھوں تری\n",
            "\n",
            "یہ جو کام رہ گئے ہیں\n",
            "اکھٹے جی رہے ہیں مگر وہ\n",
            "خود کو بھی اب سو گیا\n",
            "کہ میں رو پڑوں مرے ضبط\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}